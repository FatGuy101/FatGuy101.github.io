### ceph集群搭建

确保每台机子都有一个系统盘和两个空闲盘(没有格式化，类似刚安装上去的)，两个空闲盘大小都要大于5G

| hostname  | ip             |
| --------- | -------------- |
| server150 | 192.168.25.150 |
| server151 | 192.168.25.151 |
| server152 | 192.168.25.152 |

确认所有节点的时间 是 同步的，不同步使用 ntpdate自行调整

~~~shell
yum install -y ntpdate
ntpdate ntp.aliyun.com
~~~

添加A记录解析

~~~shell
cat > /etc/hosts << EOF
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.25.150 server150
192.168.25.151 server151
192.168.25.152 server152
192.168.25.10  server10
192.168.25.11  server11
192.168.25.12  server12
192.168.25.13  server13
EOF
~~~

关闭selinux

~~~shell
setenforce 0
sed -i '/SELINUX=/cSELINUX=disabled'    /etc/selinux/config
~~~

配置ssh免密登录

~~~shell
ssh-keygen -t rsa -P ""
ssh-copy-id server150
ssh-copy-id server151
ssh-copy-id server152
~~~

优化系统

~~~shell
vim /etc/security/limits.conf

#添加下面两行
*  soft  nofile  65535
*  hard  nofile  65535
#exit 退出重登录生效
~~~

添加ceph源

~~~shell
cat > /etc/yum.repos.d/ceph.repo << EOF
[ceph]
name=ceph
baseurl=http://mirrors.aliyun.com/ceph/rpm-octopus/el7/x86_64/
gpgcheck=0
priority=1
 
[ceph-noarch]
name=cephnoarch
baseurl=http://mirrors.aliyun.com/ceph/rpm-octopus/el7/noarch/
gpgcheck=0
priority=1
 
[ceph-source]
name=Ceph source packages
baseurl=http://mirrors.aliyun.com/ceph/rpm-octopus/el7/SRPMS
gpgcheck=0
priority=1
EOF
yum clean all
yum makecache fast
~~~

安装ceph-deploy

~~~shell
yum install -y ceph-deploy python2-pip
pip install ceph-deploy==2.0.1 -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com
~~~

150上新建集群

~~~shell
mkdir ~/ceph-cluster
cd ~/ceph-cluster/
ceph-deploy new server150 server151 server152
~~~

安装ceph组件包(自动全节点安装)

~~~shell
ceph-deploy install --no-adjust-repos server150 server151 server152
~~~

部署monitor 服务，产生相关的管理秘钥

~~~shelll
ceph-deploy mon create-initial 
~~~

将生成的相关秘钥和配置文件，统一分发到所有节点的/etc/ceph 目录中

~~~shell
ceph-deploy admin server150 server151 server152
~~~

创建OSD对象

~~~shell
ceph-deploy osd create --data /dev/sdb server150
ceph-deploy osd create --data /dev/sdb server151
ceph-deploy osd create --data /dev/sdb server152
ceph-deploy osd create --data /dev/sdc server150
ceph-deploy osd create --data /dev/sdc server151
ceph-deploy osd create --data /dev/sdc server152
~~~

部署 MGR 服务

~~~shell
ceph-deploy mgr create server150 server151 server152
~~~

使用以下命名，关闭使用不安全模式运行的提示

~~~shell
ceph config set mon auth_allow_insecure_global_id_reclaim false
~~~

所有节点安装依赖并重启

~~~shell
pip3 install pecan werkzeug -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com
systemctl restart ceph-mgr.target
~~~

查看集群

~~~shell
ceph -s
~~~

  `cluster:`
    `id:     629fd2fc-58cf-4c3e-94a3-0f6161cfedf3`
    `health: HEALTH_OK`

  `services:`
    `mon: 3 daemons, quorum server150,server151,server152 (age 8m)`
    `mgr: server150(active, since 7s), standbys: server151, server152`
    `osd: 6 osds: 6 up (since 6m), 6 in (since 6m)`

  `data:`
    `pools:   1 pools, 1 pgs`
    `objects: 0 objects, 0 B`
    `usage:   6.0 GiB used, 54 GiB / 60 GiB avail`
    `pgs:     1 active+clean`



### 启用dashboard

#### 失败作品

启动dashboard模块

~~~shell
ceph mgr module enable dashboard --force
~~~

安装插件

~~~shell
yum install -y ceph-mgr-dashboard
~~~

报错
`--> Finished Dependency ResolutionError: Package: 2:ceph-mgr-dashboard-15.2.17-0.el7.noarch (ceph-noarch)Requires: python3-cherrypyError: Package: 2:ceph-mgr-dashboard-15.2.17-0.el7.noarch (ceph-noarch)Requires: python3-routesError: Package: 2:ceph-mgr-dashboard-15.2.17-0.el7.noarch (ceph-noarch)Requires: python3-jwt`

安装依赖

~~~shell
pip3 install cherrypy routes jwt -i https://mirrors.aliyun.com/pypi/simple/
~~~

出现报错
    `Traceback (most recent call last):`
      `File "<string>", line 1, in <module>`
      `File "/tmp/pip-build-1lkzd3u1/cryptography/setup.py", line 18, in <module>`
        `from setuptools_rust import RustExtension`
    `ModuleNotFoundError: No module named 'setuptools_rust'`

安装setuptools_rust

~~~shell
pip3 install setuptools_rust cherrypy routes jwt
~~~

依旧报错
尝试曲线救国拯救

~~~shell
pip3 install -U pip setuptools -i https://mirrors.aliyun.com/pypi/simple/
~~~

再次尝试安装

~~~shell
pip3 install cherrypy routes jwt -i https://mirrors.aliyun.com/pypi/simple/
~~~

没报错了

安装插件

~~~shell
yum install -y ceph-mgr-dashboard
~~~

依旧报原来的错误



看了半天貌似没有有关于dashboard的命令

破案了ceph15的O版搞不来dashborad
要旧版本的ceph
参考 博客
https://www.cnblogs.com/LiuChang-blog/p/15615598.html

安装报错原因分析
这是由于从O版本开始，MGR改为Python3编写，而默认库没有这3个模块包，即使单独找包安装也可能不生效或者安装不上。从社区得知，这是已知问题，建议使用CentOS8系统或者使用cephadm容器化部署Ceph，或者降低Ceph版本也可以，例如H版本，这个版本还是Python2编写的，不存在缺包问题。





#### 成功作品

这里我使用快照进行还原了

然后快速进行ceph集群搭建

和之前的搭建ceph集群一样

先把系统优化好

##### 环境配置

确认所有节点的时间 是 同步的，不同步使用 ntpdate自行调整

~~~shell
yum install -y ntpdate
ntpdate ntp.aliyun.com
~~~

添加A记录解析

~~~shell
cat > /etc/hosts << EOF
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.25.150 server150
192.168.25.151 server151
192.168.25.152 server152
192.168.25.10  server10
192.168.25.11  server11
192.168.25.12  server12
192.168.25.13  server13
EOF
~~~

关闭selinux

~~~shell
setenforce 0
sed -i '/SELINUX=/cSELINUX=disabled'    /etc/selinux/config
~~~

配置ssh免密登录

~~~shell
ssh-keygen -t rsa -P ""
ssh-copy-id server150
ssh-copy-id server151
ssh-copy-id server152
~~~

优化系统

~~~shell
vim /etc/security/limits.conf

#添加下面两行
*  soft  nofile  65535
*  hard  nofile  65535
#exit 退出重登录生效
~~~

要注意的是，这里我添加N版的ceph源

~~~shell
cat > /etc/yum.repos.d/ceph.repo << EOF
[ceph]
name=ceph
baseurl=http://mirrors.aliyun.com/ceph/rpm-nautilus/el7/x86_64/
gpgcheck=0
priority=1

[ceph-noarch]
name=cephnoarch
baseurl=http://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/
gpgcheck=0
priority=1

[ceph-source]
name=Ceph source packages
baseurl=http://mirrors.aliyun.com/ceph/rpm-nautilus/el7/SRPMS
gpgcheck=0
priority=1
EOF
yum clean all
yum makecache fast
~~~

安装ceph-deploy

~~~shell
yum install -y ceph-deploy python2-pip
~~~

##### 搭建集群

server150上新建集群

~~~shell
mkdir /root/ceph-cluster
cd /root/ceph-cluster/
ceph-deploy new server150 server151 server152
~~~

安装ceph组件包(自动全节点安装)

~~~shell
ceph-deploy install --no-adjust-repos server150 server151 server152
~~~

部署monitor 服务，产生相关的管理秘钥

~~~shelll
ceph-deploy mon create-initial 
~~~

将生成的相关秘钥和配置文件，统一分发到所有节点的/etc/ceph 目录中

~~~shell
ceph-deploy admin server150 server151 server152
~~~

创建OSD对象

~~~shell
ceph-deploy osd create --data /dev/sdb server150
ceph-deploy osd create --data /dev/sdb server151
ceph-deploy osd create --data /dev/sdb server152
ceph-deploy osd create --data /dev/sdc server150
ceph-deploy osd create --data /dev/sdc server151
ceph-deploy osd create --data /dev/sdc server152
~~~

部署 MGR 服务

~~~shell
ceph-deploy mgr create server150 server151 server152
~~~

使用以下命名，关闭使用不安全模式运行的提示

~~~shell
ceph config set mon auth_allow_insecure_global_id_reclaim false
~~~

重启使配置生效

~~~shell
systemctl restart ceph-mgr.target
~~~

查看集群

~~~shell
ceph -s
~~~

  `cluster:`
    `id:     c2ff5c23-ed9c-4a7b-a70f-611dcd218c04`
    `health: HEALTH_OK`

  `services:`
    `mon: 3 daemons, quorum server150,server151,server152 (age 5h)`
    `mgr: server150(active, since 2d), standbys: server151, server152`
    `osd: 6 osds: 4 up (since 5h), 4 in (since 21h)`

  `data:`
    `pools:   0 pools, 0 pgs`
    `objects: 0 objects, 0 B`
    `usage:   4.0 GiB used, 36 GiB / 40 GiB avail`
    `pgs:`

##### 部署Dashboard

每个结点都要安装

~~~shell
yum install -y ceph-mgr-dashboard
~~~

开启dashboard模块

~~~shell
ceph mgr module enable dashboard
~~~

修改默认配置

~~~shell
# 监听地址
ceph config set mgr mgr/dashboard/server_addr 0.0.0.0
# 使用的端口
ceph config set mgr mgr/dashboard/server_port 7000
# 不使用https
ceph config set mgr mgr/dashboard/ssl false
~~~

重启使配置生效

~~~shell
ceph mgr module disable dashboard
ceph mgr module enable dashboard
~~~

创建一个dashboard登录用户名密码

账号：admin

密码：123456

~~~shell
echo "123456" > password.txt
ceph dashboard ac-user-create admin administrator -i password.txt
~~~

顺便启用Prometheus监控

~~~shell
ceph mgr module enable prometheus
~~~

查看服务方式

~~~shell
ceph mgr services
~~~

`{`
    `"dashboard": "http://server150:7000/",`
    `"prometheus": "http://server150:9283/"`
`}`

测试promtheus指标接口

~~~shell
curl 192.168.25.150:9283/metrics
~~~

配置Prometheus采集

~~~shell
vim prometheus.yml

scrape_configs:
  - job_name: 'ceph'
     static_configs:
     - targets: ['192.168.25.150:9283']
~~~

浏览器访问Dashboard

![](https://picst.sunbangyan.cn/2023/11/25/904c682e0835266461be945d48d0b36a.jpeg)

浏览器访问Prometheus

![](https://picdm.sunbangyan.cn/2023/11/25/bd06ff73bb9ec9103056d0581b04a7ef.jpeg)

![](https://picss.sunbangyan.cn/2023/11/25/03ac91a555e36a774995aec526e9ff93.jpeg)

通过grafana模板查看

Dashboards -> Manage -> Import -> 输入仪表盘ID -> Load

Ceph-Cluster ID: 2842

Ceph-OSD ID:   5336

Ceph-Pool ID:  5342





Ceph-Cluster：

![](https://picss.sunbangyan.cn/2023/11/25/0ce345fbfdbbc40bc720c86e7f23af4d.jpeg)

Ceph-OSD：

![](https://picst.sunbangyan.cn/2023/11/25/580164fde2eb7eac9f394fdd42831a42.jpeg)

Ceph-Pool：

![](https://picss.sunbangyan.cn/2023/11/25/27f6a542dc1a317bf601df5164dae079.jpeg)